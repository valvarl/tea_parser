"""
–§–æ–Ω–æ–≤–∞—è –∫–æ—Ä—É—Ç–∏–Ω–∞, –∫–æ—Ç–æ—Ä—É—é –∑–∞–ø—É—Å–∫–∞–µ—Ç FastAPI `BackgroundTasks`.
–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª: —Å–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞—á—É ‚Üí –∑–∞–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞—É–∑–µ—Ä ‚Üí
—Å–ø–∞—Ä—Å–∏—Ç—å –ø—Ä–æ–¥—É–∫—Ç—ã ‚Üí —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å / –æ–±–Ω–æ–≤–∏—Ç—å –≤ MongoDB ‚Üí –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
–∑–∞–≤–µ—Ä—à–∏—Ç—å –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å.
"""

from __future__ import annotations

import asyncio
import logging
from datetime import datetime
from typing import Dict

from app.db.mongo import db
from app.models.task import ScrapingTask
from app.models.tea import TeaProduct
from app.services.indexer import indexer  # –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä ProductIndexer

logger = logging.getLogger(__name__)


async def scrape_tea_products_task(search_term: str, task_id: str) -> None:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ –∏–∑ —ç–Ω–¥-–ø–æ–π–Ω—Ç–∞ `/scrape/start`.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        search_term: —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞ Ozon
        task_id:     –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä ScrapingTask –≤ Mongo
    """

    async def _update_task(patch: Dict) -> None:
        """–£–¥–æ–±–Ω—ã–π —Ö–µ–ª–ø–µ—Ä –¥–ª—è –ø–∞—Ç—á–µ–π –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ `scraping_tasks`."""
        await db.scraping_tasks.update_one({"id": task_id}, {"$set": patch})

    # ‚Äî‚Äî‚Äî —Å—Ç–∞—Ç—É—Å ¬´running¬ª ‚Äî‚Äî‚Äî #
    await _update_task({"status": "running", "started_at": datetime.utcnow()})
    logger.info("üöÄ Scraping task %s started (query='%s')", task_id, search_term)

    scraped_count = failed_count = 0

    try:
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±—Ä–∞—É–∑–µ—Ä –∏ –∏—â–µ–º —Ç–æ–≤–∞—Ä—ã
        products = await indexer.search_products(search_term, max_pages=3)
        total_products = len(products)

        logger.info("üìä %d products found for query '%s'", total_products, search_term)

        if not products:
            await _update_task(
                {
                    "status": "completed",
                    "completed_at": datetime.utcnow(),
                    "total_products": 0,
                    "error_message": "No products found (geo-blocking or API change?)",
                }
            )
            return

        # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä
        for idx, prod in enumerate(products, 1):
            try:
                if not prod.get("name"):
                    raise ValueError("product without name")

                tea = TeaProduct(**prod)

                # upsert –ø–æ ozon_id (–µ—Å–ª–∏ –µ—Å—Ç—å) –ª–∏–±–æ –ø–æ id (fallback)
                query = {"ozon_id": tea.ozon_id} if tea.ozon_id else {"id": tea.id}
                exists = await db.tea_products.find_one(query)

                if exists:
                    tea.updated_at = datetime.utcnow()
                    await db.tea_products.update_one(query, {"$set": tea.dict()})
                else:
                    await db.tea_products.insert_one(tea.dict())

                scraped_count += 1
            except Exception as exc:  # pragma: no cover
                logger.exception("‚ùå error on product %d/%d: %s", idx, total_products, exc)
                failed_count += 1
            finally:
                # –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ
                if idx % 5 == 0 or idx == total_products:
                    await _update_task(
                        {
                            "scraped_products": scraped_count,
                            "failed_products": failed_count,
                            "total_products": total_products,
                        }
                    )

        # 3. –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        await _update_task(
            {
                "status": "completed",
                "completed_at": datetime.utcnow(),
                "scraped_products": scraped_count,
                "failed_products": failed_count,
                "total_products": total_products,
            }
        )
        logger.info(
            "üéâ Task %s finished: %d scraped, %d failed",
            task_id,
            scraped_count,
            failed_count,
        )

    except Exception as exc:  # pragma: no cover
        logger.exception("üî• critical error in task %s: %s", task_id, exc)
        await _update_task(
            {
                "status": "failed",
                "completed_at": datetime.utcnow(),
                "error_message": str(exc),
            }
        )

    finally:
        # 4. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
        try:
            await indexer.close_browser()
        except Exception:  # pragma: no cover
            logger.warning("could not close browser in task %s", task_id)

        # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã —Ñ–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ FastAPI –¥–æ—à—ë–ª –¥–æ –∫–æ–Ω—Ü–∞
        await asyncio.sleep(0.1)
