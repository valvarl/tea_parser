from __future__ import annotations

import asyncio, json, logging, os, uuid
from datetime import datetime
from typing import Dict, Any

from aiokafka import AIOKafkaProducer, AIOKafkaConsumer
from app.db.mongo import db
from app.models.task import ScrapingTask

logger = logging.getLogger(__name__)

BOOT      = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092")
TOPIC_CMD = os.getenv("TOPIC_INDEXER_CMD", "indexer_cmd")
TOPIC_ST  = os.getenv("TOPIC_INDEXER_STATUS", "indexer_status")


async def scrape_tea_products_task(search_term: str, task_id: str) -> None:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–º–∞–Ω–¥—É indexer-–≤–æ—Ä–∫–µ—Ä—É –∏ —Å–ª—É—à–∞–µ–º —Å—Ç–∞—Ç—É—Å-–∏–≤–µ–Ω—Ç—ã.
    MongoDB-insert —Å–∞–º –≤–æ—Ä–∫–µ—Ä; –∑–¥–µ—Å—å –ª–∏—à—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ ScrapingTask.
    """

    async def patch(p: Dict[str, Any]) -> None:
        await db.scraping_tasks.update_one({"id": task_id}, {"$set": p})

    # 0. —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ñ–∞–∫—Ç –∑–∞–¥–∞—á–∏
    await patch({"status": "queued", "created_at": datetime.utcnow()})

    # 1. Producer ‚Üí command
    producer = AIOKafkaProducer(
        bootstrap_servers=BOOT,
        value_serializer=lambda x: json.dumps(x).encode(),
        acks="all",
        enable_idempotence=True,
    )
    await producer.start()
    await producer.send_and_wait(
        TOPIC_CMD,
        {"task_id": task_id, "search_term": search_term},
    )
    await producer.stop()
    logger.info("üì§ sent command for task %s (%s)", task_id, search_term)

    # 2. Consumer ‚Üê status
    consumer = AIOKafkaConsumer(
        TOPIC_ST,
        bootstrap_servers=BOOT,
        group_id=f"task-monitor-{uuid.uuid4()}",
        value_deserializer=lambda x: json.loads(x.decode()),
        auto_offset_reset="earliest",
        enable_auto_commit=True,
    )
    await consumer.start()

    try:
        async for msg in consumer:
            st: Dict[str, Any] = msg.value
            if st.get("task_id") != task_id:
                continue                              # –¥—Ä—É–≥–æ–µ –∑–∞–¥–∞–Ω–∏–µ

            # –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–ª–∏ —Ñ–∏–Ω–∞–ª ‚Äî –ø–∞—Ç—á–∏–º –¥–æ–∫—É–º–µ–Ω—Ç
            await patch(st | {"updated_at": datetime.utcnow()})

            if st.get("status") in {"completed", "failed"}:
                logger.info("üèÅ task %s finished (%s)", task_id, st["status"])
                break
    finally:
        await consumer.stop()

# async def scrape_tea_products_task(search_term: str, task_id: str) -> None:
    # """
    # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ –∏–∑ —ç–Ω–¥-–ø–æ–π–Ω—Ç–∞ `/scrape/start`.

    # –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
    #     search_term: —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞ Ozon
    #     task_id:     –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä ScrapingTask –≤ Mongo
    # """

    # async def _update_task(patch: Dict) -> None:
    #     """–£–¥–æ–±–Ω—ã–π —Ö–µ–ª–ø–µ—Ä –¥–ª—è –ø–∞—Ç—á–µ–π –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ `scraping_tasks`."""
    #     await db.scraping_tasks.update_one({"id": task_id}, {"$set": patch})

    # # ‚Äî‚Äî‚Äî —Å—Ç–∞—Ç—É—Å ¬´running¬ª ‚Äî‚Äî‚Äî #
    # await _update_task({"status": "running", "started_at": datetime.utcnow()})
    # logger.info("üöÄ Scraping task %s started (query='%s')", task_id, search_term)

    # scraped_count = failed_count = 0

    # try:
    #     # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±—Ä–∞—É–∑–µ—Ä –∏ –∏—â–µ–º —Ç–æ–≤–∞—Ä—ã
    #     products = await indexer.search_products(search_term, max_pages=3)
    #     total_products = len(products)

    #     logger.info("üìä %d products found for query '%s'", total_products, search_term)

    #     if not products:
    #         await _update_task(
    #             {
    #                 "status": "completed",
    #                 "completed_at": datetime.utcnow(),
    #                 "total_products": 0,
    #                 "error_message": "No products found (geo-blocking or API change?)",
    #             }
    #         )
    #         return

    #     # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä
    #     for idx, prod in enumerate(products, 1):
    #         try:
    #             if not prod.get("name"):
    #                 raise ValueError("product without name")

    #             tea = TeaProduct(**prod)

    #             # upsert –ø–æ ozon_id (–µ—Å–ª–∏ –µ—Å—Ç—å) –ª–∏–±–æ –ø–æ id (fallback)
    #             query = {"ozon_id": tea.ozon_id} if tea.ozon_id else {"id": tea.id}
    #             exists = await db.tea_products.find_one(query)

    #             if exists:
    #                 tea.updated_at = datetime.utcnow()
    #                 await db.tea_products.update_one(query, {"$set": tea.dict()})
    #             else:
    #                 await db.tea_products.insert_one(tea.dict())

    #             scraped_count += 1
    #         except Exception as exc:  # pragma: no cover
    #             logger.exception("‚ùå error on product %d/%d: %s", idx, total_products, exc)
    #             failed_count += 1
    #         finally:
    #             # –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ
    #             if idx % 5 == 0 or idx == total_products:
    #                 await _update_task(
    #                     {
    #                         "scraped_products": scraped_count,
    #                         "failed_products": failed_count,
    #                         "total_products": total_products,
    #                     }
    #                 )

    #     # 3. –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
    #     await _update_task(
    #         {
    #             "status": "completed",
    #             "completed_at": datetime.utcnow(),
    #             "scraped_products": scraped_count,
    #             "failed_products": failed_count,
    #             "total_products": total_products,
    #         }
    #     )
    #     logger.info(
    #         "üéâ Task %s finished: %d scraped, %d failed",
    #         task_id,
    #         scraped_count,
    #         failed_count,
    #     )

    # except Exception as exc:  # pragma: no cover
    #     logger.exception("üî• critical error in task %s: %s", task_id, exc)
    #     await _update_task(
    #         {
    #             "status": "failed",
    #             "completed_at": datetime.utcnow(),
    #             "error_message": str(exc),
    #         }
    #     )

    # finally:
    #     # 4. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
    #     try:
    #         await indexer.close_browser()
    #     except Exception:  # pragma: no cover
    #         logger.warning("could not close browser in task %s", task_id)

    #     # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã —Ñ–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ FastAPI –¥–æ—à—ë–ª –¥–æ –∫–æ–Ω—Ü–∞
    #     await asyncio.sleep(0.1)
